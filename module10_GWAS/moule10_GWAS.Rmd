---
title: "module10_GWAS"
author: "Ruijuan Li"
date: "July 20, 2016"
output: html_document
---

# 1) session 1 
```{r}
setwd("/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/")
LHON=read.table("http://faculty.washington.edu/tathornt/sisg/LHON.txt",header=TRUE)
### View the first few lines of the LHON data

head(LHON)

### For computers using Rstudio, could also use the View command #

#View(LHON)


### Take a closer look at the types of variables in the LHON data frame

str(LHON)

# Question 2: Perform logistic regression.  Obtain odds ratios and confidence intervals

# Create a 0 and 1 phenotype variable indicating Case/Control Status to perform a logistic regression analysis


LHON$newpheno=with(LHON,ifelse(PHENO=="CASE",1,0))


## What would be the reference genotype for a logistic regression analysis?  The first factor will be the reference genotype.

levels(LHON$GENO)

# Perform a logistic regression analysis

model1=glm(newpheno~GENO,family=binomial(link="logit"),data=LHON)
?glm

# View the summary results of the logistic regression model, including parameter estimates and standard errors  

summary(model1)

#  Obtain odds ratio and a 95% confidence interval for CT the reference genotype CC  ## 


# summary(model1)
#
#Call:
#glm(formula = newpheno ~ GENO, family = binomial(link = "logit"),data = LHON)
#
#Deviance Residuals: 
#    Min       1Q   Median       3Q      Max  
#-0.9695  -0.8701  -0.8701   1.5197   2.1093  
#
#Coefficients:
#            Estimate Std. Error z value Pr(>|z|)  
#(Intercept)  -0.5108     0.5164  -0.989   0.3226  
#GENOCT       -1.5994     0.6378  -2.508   0.0122 *
#GENOTT       -0.2654     0.5349  -0.496   0.6197  
#---
#Signif. codes:  0 ???***??? 0.001 ???**??? 0.01 ???*??? 0.05 ???.??? 0.1 ??? ??? 1 
#
#(Dispersion parameter for binomial family taken to be 1)
#
#    Null deviance: 383.49  on 327  degrees of freedom
#Residual deviance: 368.48  on 325  degrees of freedom
#AIC: 374.48
#
#Number of Fisher Scoring iterations: 4


## WHAT is the odds ratio for the CT genotype?

exp(-1.5994)

# Obtain a confidence interval for the  odss ratio parameter for the CT genotype

myse=1.96*(.6378)

CI=c(-1.5994-myse,-1.5994+myse)

exp(CI)

# Similarly can obtain a confidence interval for the odds ratio for the TT genotype

exp(-.2654)

myse=1.96*(.5349)

CI=c(-.2654-myse,-.2654+myse)
exp(CI)




## Question 3: Redo the association analysis but use TT as the reference genotype  ##

# Hint: Use the relevel function to create a new genotype vector with reference genotype TT

LHON$NEWGENO=with(LHON,relevel(GENO, ref = "TT"))


levels(LHON$NEWGENO)

### Perform logistic regression using 
model2=glm(newpheno~NEWGENO,family=binomial(link="logit"),data=LHON)
summary(model2) # odd ratio depends on your reference. 


exp(-1.3340 )

myse=1.96*(.3995)

CI=c(-1.3340-myse,-1.3340+myse)
exp(CI)


#  could also do the following to get 95% confidence interval of parameters from your model

MYCI=confint.default(model2)
exp(MYCI)


### Why are the odds ratios different for CT now?  Explain? 
# 1) because you chang ref from CC to TT, odds ratio depends on reference. 
### Plot the data for a better understanding

plot(factor(PHENO)~factor(GENO), data=LHON)
# by looking at the plot, you can find that there is fewer data in CC, sample size 
# is small, which can introduce higher errors. 

#How about an additive logistic regression model?  

LHON$genoadd <- with(LHON, 0 + 1*(GENO=="CT") + 2*(GENO=="TT"))
 
model3 <- glm(newpheno~genoadd,family=binomial(link="logit"),data=LHON)
summary(model3) 


```

# session 2  
```{r}
# session 2 commands

bpdata=read.csv("http://faculty.washington.edu/tathornt/sisg/bpdata.csv",header=TRUE)

# Question 1: linear regression different models

#additive model, only the number of alleles matters 
head(bpdata)
bpdata$n.minor <- (bpdata$snp3=="TC") + (bpdata$snp3=="CT")+ 2*(bpdata$snp3=="TT")
# true as 1 and false as 0 in R 
lm1 = lm(sbp~n.minor, data=bpdata)

# obtain a confidence interval for the linear regression paramaters
confint.default(lm1)
summary(lm1)

#dominant effect of T
bpdata$domvar <- (bpdata$snp3=="TC") | (bpdata$snp3=="TT") # one copy of T allele has 
# same effect of 2 T alleles. 

with(bpdata, table(domvar, snp3)) # table function in R 

lm2 <- lm(sbp~domvar, data=bpdata) 
confint.default(lm2)
summary(lm2)

#Do linear regression analysis assuming a recessive model and assuming a two-degree of freedom model (genotypic model)

# Question 2: Plots
plot(sbp~jitter(n.minor), data=bpdata,col="darkgreen")
abline(lm1, col="red", lwd=2)

boxplot(sbp~n.minor,data=bpdata, col=c("purple","red","darkblue"))
abline(lm1, lwd=2)

## question 3 ##

lm1adj = lm(sbp~n.minor+sex+bmi, data=bpdata) # by including sex, increase the precision of linear regression, get better estimate 
#Get confidence intervals and summary data #

## question 4##
## Perform a linear regression for additive model using all SNPs

# 2 degree of freedom model 
lm3 <- lm(sbp ~ snp3, data = bpdata) # sample size and standard error problem... 
summary(lm3)

# ressesive model 
bpdata$recessive <- (bpdata$snp3=="TT")
lmrec <- lm(sbp ~ recessive, data = bpdata)
summary(lmrec)
```

# session 3
```{r}
setwd("/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/data/SISG_Files/Data_Files/")

## A few R commands for summary statistics for phenotype ##
##  count number of individuals in the study
FAM<-read.table(file="Transferrin.fam",sep=" ", header=FALSE,na="NA")
head(FAM)
dim(FAM)

## Map Information on number of SNPS count number of genotyped SNPs
map<-read.table(file="Transferrin.bim",sep="\t", header=FALSE,na="NA") # SNP data 
head(map) 
dim(map)

## Obtain some basic Info on transferrin phenotype  
TPHENO<-read.table(file="Tr.pheno", header=FALSE)

head(TPHENO) 
dim(TPHENO)

# Give names to PHENO variables  

names(TPHENO)=c("FAMID", "ID", "Transferrin")
head(TPHENO)

###Summary information and histrogram of transferrin pheno

summary(TPHENO$Transferrin)
table(is.na(TPHENO$Transferrin))

hist(TPHENO$Transferrin, xlab="Transferrin",main="Histogram of Transferrin")

## GET INFO on height phenotype  (standardized and adjusted for relevant covariates)
 
HPHENO = read.table(file="Ht.pheno.txt", header=FALSE)

head(HPHENO)
dim(HPHENO)

names(HPHENO)=c("FAMID", "ID", "Height")
head(HPHENO)

###Summary information and histrogram of height
summary(HPHENO$Height)
table(is.na(HPHENO$Height))

hist(HPHENO$Height, xlab="Height",main="Histogram of Height")

##### After you run the PLINK association analysis, use the commands below #######

# If the R package GWASTools has not yet been installed on your computer, install the R package using the commands below 

# source("http://bioconductor.org/biocLite.R")
# biocLite("GWASTools")

### Load the GWASTools package to your R session so that we can use the plotting functions for this package ###

library(GWASTools)

### Read in the Association Results from PLINK for Height

Height.Assoc=read.table("/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/plink-1.07-mac-intel/GWAS_H_add.qassoc",header=TRUE)	

head(Height.Assoc)

#### Obtain a Manhattan plot using GWAS tools ####

manhattanPlot(p=Height.Assoc$P,chromosome=Height.Assoc$CHR, main="Association Results for Height")

### can create a Manhattan plot for just the autosomes ###

AHeight.Assoc=subset(Height.Assoc,CHR<=22)

manhattanPlot(p=AHeight.Assoc$P,chromosome=AHeight.Assoc$CHR, main="Association Results for Autosomes for Height")

#### Obtain a Q-Q plot using GWAS tools ####

qqPlot(pval=Height.Assoc$P)

### Can also us the qqman package to obtain a manhattan plot ###

# install.packages("qqman")
library("qqman")
vignette("qqman")

manhattan(Height.Assoc)
qq(Height.Assoc$P)

### IDENTIFY TOP 10 SNPS  for Height  ###
head(Height.Assoc)
dim(Height.Assoc)		## number of SNPS analyzed

TOP <- Height.Assoc[order(Height.Assoc$P),] 
head(TOP,10)

### Similarly obtain plots and top SNPs for Transferrin ### 
```

# session 4 
```{r}
### R Scripts : Reading data into R and getting rid of missing phenotypes

snps = read.table("/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/plink-1.07-mac-intel/TFsnps.raw", header = T) 
phenotypes = read.table("/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/data/SISG_Files/Data_Files/Tr.pheno", header = F)

missing.phenotypes = which(is.na(phenotypes[,3]))
Z = as.matrix(snps[-missing.phenotypes,7:30])
y = as.vector(phenotypes[-missing.phenotypes,3])


##################################################################################################################
##################################################################################################################


### R Scripts: find out home much missing data we have in the SNPs, and then omit the samples with missing SNPs

sum(is.na(Z)) ## this gives us the number of SNPs that are missing

w.missing = which(apply(is.na(Z),1,sum) > 0) ## This figures out which subjects have ANY missing values

Z = Z[-w.missing,]  ## now we get rid of the subjects with any missing SNPs
y = y[-w.missing]   ## BE CAREFUL: because we are over-writing the variable, don't run this line more than once by accident.

sum(is.na(Z))
sum(is.na(y)) ## Now we see that there is no missingness in either the Z or the y.


##################################################################################################################
##################################################################################################################
### R Scripts: minP tests


pvals = rep(NA, ncol(Z))
for (j in 1:ncol(Z)) {
  pvals[j] = summary(lm(y~Z[,j]))$coef[2,4]  ### this gets the p-value for the association between the j-th snp and y
}


min.pvalue = min(pvals) ## This actually runs the previous function

min.pvalue  ## This is the unadjusted minimum p-value

bonf.pvalue = min(min.pvalue*ncol(Z), 1) ## this is the bonferroni adjusted minimum p-value

### since unadjusted is way too liberal and bonferroni can be way to conservative, let's try getting some sense
### of the "effective number of tests".  We'll try the PCA approach, though many others are possible

getEffectiveSampSize.PCA = function(Z, proportionVariability = 0.99) {
## this function will estimate the number of PCs necessary to explain a certain proportion of the variability
## Z is the matrix of genotypes and proportionVariability is the proportion of variability we want to explain.

  pca = prcomp(Z) ### Does principal component analysis
  evs = pca$sdev**2/sum(pca$sdev**2) ## represents the proportion of variability that is explained by each component
  return(min(which(cumsum(evs)>= proportionVariability)))
}

eff90pct = getEffectiveSampSize.PCA(Z, 0.90)
eff95pct = getEffectiveSampSize.PCA(Z, 0.95)
eff99pct = getEffectiveSampSize.PCA(Z, 0.99)
eff99.9pct = getEffectiveSampSize.PCA(Z, 0.999)

p90pct = min(eff90pct*min.pvalue, 1)
p95pct = min(eff95pct*min.pvalue, 1)
p99pct = min(eff99pct*min.pvalue, 1)
p99.9pct = min(eff99.9pct*min.pvalue, 1)

cbind(c(p90pct, p95pct,p99pct, p99.9pct), c(90,95,99,99.9))

### Note that there is tremendous heterogeneity in the p-values.  Although they are all significant, it's not clear which is the best.

##################################################################################################################
##################################################################################################################
### R Scripts: averaging/collapsing tests

### let's first collapse the SNPs into a simple average or sum of the variants within the region

C = apply(Z, 1, sum) ## This sums each row of Z
hist(C)

summary(lm(y~C))  ## This gives us the association between the averaged/summed SNP value and the outcome y

### Now let's take the top principal component

pca = prcomp(Z)       ### find eigen decomposition
pc1 = Z%*%pca$rot[,1] ### computes the top principal component

summary(lm(y~pc1)) ## Gives us the association


##################################################################################################################
##################################################################################################################
###---***---***---###---***---***---###---***---***---###---***---***---###---***---***---###---***---***---###
###---***---***---###---***---***---###---***---***---###---***---***---###---***---***---###---***---***---###
##################################################################################################################
##################################################################################################################


##################################################################################################################
##################################################################################################################
### R Scripts: Now let's repeat everything with just some random segment of the genome

snps = read.table("/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/plink-1.07-mac-intel/randomSegment.raw", header = T) 
phenotypes = read.table("/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/data/SISG_Files/Data_Files/Tr.pheno", header = F)

missing.phenotypes = which(is.na(phenotypes[,3]))
Z = as.matrix(snps[-missing.phenotypes,7:247])
y = as.vector(phenotypes[-missing.phenotypes,3])



##################################################################################################################
##################################################################################################################
### R Scripts: find out home much missing data we have in the SNPs, and then omit the samples with missing SNPs

sum(is.na(Z)) ## this gives us the number of SNPs that are missing

w.missing = which(apply(is.na(Z),1,sum) > 0) ## This figures out which subjects have ANY missing values

Z = Z[-w.missing,]  ## now we get rid of the subjects with any missing SNPs
y = y[-w.missing]   ## BE CAREFUL: because we are over-writing the variable, don't run this line more than once by accident.

sum(is.na(Z))
sum(is.na(y)) ## Now we see that there is no missingness in either the Z or the y.

##################################################################################################################
##################################################################################################################
### R Scripts: minP tests


pvals = rep(NA, ncol(Z))
for (j in 1:ncol(Z)) {
  pvals[j] = summary(lm(y~Z[,j]))$coef[2,4]  ### this gets the p-value for the association between the j-th snp and y
}


min.pvalue = min(pvals) ## This actually runs the previous function

min.pvalue  ## This is the unadjusted minimum p-value

bonf.pvalue = min(min.pvalue*ncol(Z), 1) ## this is the bonferroni adjusted minimum p-value

### since unadjusted is way too liberal and bonferroni can be way to conservative, let's try getting some sense
### of the "effective number of tests".  We'll try the PCA approach, though many others are possible

getEffectiveSampSize.PCA = function(Z, proportionVariability = 0.99) {
## this function will estimate the number of PCs necessary to explain a certain proportion of the variability
## Z is the matrix of genotypes and proportionVariability is the proportion of variability we want to explain.

  pca = prcomp(Z) ### Does principal component analysis
  evs = pca$sdev**2/sum(pca$sdev**2) ## represents the proportion of variability that is explained by each component
  return(min(which(cumsum(evs)>= proportionVariability)))
}

eff90pct = getEffectiveSampSize.PCA(Z, 0.90)
eff95pct = getEffectiveSampSize.PCA(Z, 0.95)
eff99pct = getEffectiveSampSize.PCA(Z, 0.99)
eff99.9pct = getEffectiveSampSize.PCA(Z, 0.999)

p90pct = min(eff90pct*min.pvalue, 1)
p95pct = min(eff95pct*min.pvalue, 1)
p99pct = min(eff99pct*min.pvalue, 1)
p99.9pct = min(eff99.9pct*min.pvalue, 1)

cbind(c(p90pct, p95pct,p99pct, p99.9pct), c(90,95,99,99.9))

### Note that there is tremendous heterogeneity in the p-values.  Although they are all significant, it's not clear which is the best.

##################################################################################################################
##################################################################################################################
### R Scripts: averaging/collapsing tests

### let's first collapse the SNPs into a simple average or sum of the variants within the region

C = apply(Z, 1, sum) ## This sums each row of Z
hist(C)

summary(lm(y~C))  ## This gives us the association between the averaged/summed SNP value and the outcome y

### Now let's take the top principal component

pca = prcomp(Z)       ### find eigen decomposition
pc1 = Z%*%pca$rot[,1] ### computes the top principal component

summary(lm(y~pc1)) ## Gives us the association
```

# session 5 
```{r}
### Install the Bioconductor R packages gdsfmt and SNPRelate ###

# source("http://bioconductor.org/biocLite.R")
#biocLite("gdsfmt")
# biocLite("SNPRelate")

#Load the pakcages gdsfmt and SNPRelate into your R session #

library(gdsfmt)
library(SNPRelate) 
## Set your working directory to where the files are located

setwd("/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/data/SISG_Files/Data_Files/")

## Investigate the contents of the PLINK files .fam and .bim files ##

##  count number of individuals in the study

FAM<-read.table(file="YRI_CEU_ASW_MEX_NAM.fam",sep=" ", header=FALSE,na="NA")
head(FAM)
dim(FAM)
unique(FAM$V1)

## Map Information on number of SNPS 

map<-read.table(file="YRI_CEU_ASW_MEX_NAM.bim",sep="\t", header=FALSE,na="NA")
head(map)
dim(map)

## File with Information on Populations of Sample Individuals
POPINFO=read.table(file="Population_Sample_Info.txt",header=TRUE)

## Obtain the number of sample individuals from each population
table(POPINFO$Population)

## Check to make sure the order of individuals is the same as the PLINK file
sum(POPINFO$IID!=FAM$V2)

## NOW Use functions in the gdsfmt and SNPRelate packages to perform a PCA ###
## A tutorial on gdsfmt and SNPRelate can be found at:
##  http://corearray.sourceforge.net/tutorials/SNPRelate/
##  Create a GDS file for R from the PLINK files

bedfile<-"/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/data/SISG_Files/Data_Files/YRI_CEU_ASW_MEX_NAM.bed" 
famfile<-"/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/data/SISG_Files/Data_Files/YRI_CEU_ASW_MEX_NAM.fam" 
bimfile<-"/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/data/SISG_Files/Data_Files/YRI_CEU_ASW_MEX_NAM.bim" 

## Convert PLINK FILES INTO GDS FORMAT FOR R
snpgdsBED2GDS(bedfile, famfile, bimfile, "IPCgeno.gds")
?snpgdsBED2GDS
## Open the GDS file
genofile <- snpgdsOpen("IPCgeno.gds")
?snpgdsOpen
head(genofile)

head(read.gdsn(index.gdsn(genofile, "sample.id")))
head(read.gdsn(index.gdsn(genofile, "snp.id")))

## Extract genotype for a specific SNP
g <- snpgdsGetGeno(genofile, snp.id="rs3813199")
?snpgdsGetGeno
hist(g)

## Now perform a PCA using a function from the SNPRelate package
pca <- snpgdsPCA(genofile)
?snpgdsPCA
tab <- data.frame(sample.id = pca$sample.id,
    EV1 = pca$eigenvect[,1],    # the first eigenvector
    EV2 = pca$eigenvect[,2],    # the second eigenvector
    stringsAsFactors = FALSE)
head(tab)

plot(tab$EV2, tab$EV1, xlab="eigenvector 2", ylab="eigenvector 1")

## NOW INCORPORATE THE POPULATION MEMBERSHIPS IN THE PCA PLOT
##  Get sample id
sample.id <- read.gdsn(index.gdsn(genofile, "sample.id"))
population=POPINFO$Population

tab <- data.frame(sample.id = pca$sample.id,
    pop = factor(population)[match(pca$sample.id, sample.id)],
    EV1 = pca$eigenvect[,1],    # the first eigenvector
    EV2 = pca$eigenvect[,2],    # the second eigenvector
    stringsAsFactors = FALSE)
head(tab, 100)

plot(tab$EV2, tab$EV1, col=as.integer(tab$pop), xlab="eigenvector 2", ylab="eigenvector 1", main="PCA using all SNPs")
legend("topleft", legend=levels(tab$pop), pch="o", col=1:(nlevels(tab$pop)))

## Now make scatterplots of the top 4 PCs with proportional variance explained included
pc.percent <- pca$varprop*100
head(round(pc.percent, 2))
lbls <- paste("PC", 1:4, "\n", format(pc.percent[1:4], digits=2), "%", sep="")
pairs(pca$eigenvect[,1:4], col=tab$pop, labels=lbls)

## Do we need 150K SNPs for population structure infererence in this sample?
##Identify a subset of SNPs based on LD threshold of 0.2 
snpset <- snpgdsLDpruning(genofile, ld.threshold=0.2)

snpset.id <- unlist(snpset)
length(snpset.id)

## Now perform a PCA with the subset of SNPs
pca2 <- snpgdsPCA(genofile, snp.id=snpset.id)

tab2 <- data.frame(sample.id = pca2$sample.id,
    pop = factor(population)[match(pca2$sample.id, sample.id)],
    EV1 = pca2$eigenvect[,1],    # the first eigenvector
    EV2 = pca2$eigenvect[,2],    # the second eigenvector
    stringsAsFactors = FALSE)

plot(tab2$EV2, tab2$EV1, col=as.integer(tab$pop), xlab="eigenvector 2", ylab="eigenvector 1", main="PCA using a subset of SNPs")
legend("bottomright", legend=levels(tab$pop), pch="o", col=1:(nlevels(tab$pop)))

##   Estimate proportional Native American and European Ancestry for the MXL from the PCA.  ## ASSUME THAT MXL have negligible African Ancestry.

avgCEU2=mean(pca2$eigenvect[population=="CEU",2])
avgNAM2=mean(pca2$eigenvect[population=="NAM",2])

MXLadmix=(pca2$eigenvect[population=="MXL",2]-avgNAM2)/(avgCEU2-avgNAM2)

### NOW MAKE A BARPLOT OF MXL  ESTIMATED ANCESTRY FROM THE PCA ###
tab2=cbind(MXLadmix,1-MXLadmix)
myorder=order(MXLadmix)
temp=t(as.matrix(tab2[myorder,]))

barplot(temp, col=c("blue","green"),xlab="Individual ", ylab="Ancestry", border=NA,axisnames=FALSE,main="Ancestry of MXL",ylim=c(0,1))
legend("bottomright", c("European","Native American"), lwd=4, col=c("blue","green"), bg="white",cex=0.85)
```

# session 6 
```{r}
#### BELOW IS THE PLINK COMMANDS USED CREATE A PLINK Genotype file in TPED format TO BE CONVERTED BY THE R PROGRAM GenABEL; R COMMANDS TO CONVERT THE 
# GenABEL FORMATTED GENOTYPE FILE AND CREATE A GENETIC RELAITONSHIP MATRIX.  ##

##  It is computationally intensive to create the PLINK TPED and GenABEL FILES, so the final GenABEL files have been provided for you.  You can start  this demo using the commands in the middle of the document where the GenABEL files are read into the R session for the linear mixed  model association analysis with GenABEL.  $$

#### FIRST USE PLINK TO   OBTAIN A TPED FILE for the Transferrin data that can be used with the GenABEL package in R  ###

#./plink  --bfile Transferrin  --maf 0.05 --geno 0.01 --hwe 0.001   --recode --transpose  --out Transposed_Transferrin  --noweb


### R commands ###

setwd("/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/data/") 

## Install the package GenABEL if it is not already installed on your computer

# install.packages("GenABEL")

# Load the GenABEL library to your R session  #
library(GenABEL)

# Convert 
#convert.snp.tped(tped="Transposed_Transferrin.tped",tfam="Transposed_Transferrin.tfam", out="GenAbel_Transferrin.raw",strand="+")

## Obtain some basic Info on transferrin phenotype  

#mydata<-read.table(file="Tr.pheno", header=FALSE)
#names(mydata)=c("FID","IID","Transferrin")
#id=mydata$IID
#Transferrin=mydata$Transferrin


#mydata<-read.table(file="Ht.pheno", header=FALSE)
#names(mydata)=c("FID","IID","Height")
#id=mydata$IID
#Height=mydata$Height


#FAM<-read.table(file="Transposed_Transferrin.tfam",sep=" ", header=FALSE,na="NA")
#names(FAM)=c("FID","IID","PID1","PID2","SEX","Dummy")
#sex=FAM$SEX-1


#### Create a table with just individual ID, Sex, and the two phenotypes ###

#mydata2=data.frame(id,sex,Transferrin,Height)

### Save this file that can be read in ###
#write.table(mydata2,"Transferrin_Height.dat",row.names=FALSE,col.names=TRUE,quote=FALSE)


#Transferrin.GR<- load.gwaa.data(phe="Transferrin_Height.dat",gen="GenAbel_Transferrin.raw")

### Save this file so that it can be read in at a time with having to recreate the object
#save(Transferrin.GR,file="Transferrin_GRAMMAR.Rdata")

### Create The Genetic Relationship Matix (GRM):  This is very computationally intensive!  Will take serveral hours on a laptop!  #####

#Transferrin.gkin <- ibs(Transferrin.GR[, autosomal(Transferrin.GR)], weight="freq")

### Save the GRM so that it does not have to be created again for future analyses ###

#save(Transferring.gkin,file="GRM_Transferrin_GRAMMAR.Rdata")


########################################################################################################
#### START HERE TO READ IN THE GenAbel formatted files and perform the GWAS with linear mixed models ###
########################################################################################################


## Set your working directory to where the files are located

setwd("/Users/tathornt/Documents/SISG_2016_Analysis")


# Install the package GenABEL if it is not already installed on your computer $

install.packages("GenABEL")   

# Load the GenABEL library to your R session  #

library(GenABEL)

load("Transferrin_GRAMMAR.Rdata")
load("GRM_Transferrin_GRAMMAR.Rdata")


descriptives.trait(Transferrin.GR)
descriptives.marker(Transferrin.GR)

#### Get the variance components of the traits for the Linear Mixed Model Analysis  #####


h2a <- polygenic(Transferrin,Transferrin.GR,kin=Transferrin.gkin)
h2b <- polygenic(Height,Transferrin.GR,kin=Transferrin.gkin)
?polygenic

### heritability estimate for transferrin ###
h2a$esth2

#> h2a$esth2
#[1] 0.4959505


### heritability estimate for height###
h2b$esth2

#> h2b$esth2 # 77% variation can be explained genetic data 
#[1] 0.7681223


### Now perform the LMM Association analysis ###
grGamma.Transferrin<- grammar(h2a,data=Transferrin.GR,method="gamma")
grGamma.Height<- grammar(h2b,data=Transferrin.GR,method="gamma")

?grammar

### Now use the output and the GWASTools package to obtain plots  ### 
library(GWASTools)


### Create a dataframe with  association results for Transferrin ###

myrow=row.names(grGamma.Transferrin)

mydata=grGamma.Transferrin[,c(1,2,6,7,8,9,10)]

mydata2=data.frame(myrow,mydata)

mydata2=mydata2[,c(2,1,3,4,5,6,7,8)]
names(mydata2)=c("CHR","SNP", "BP", "N", "BETA", "SE","chi2.1df","P1df")

TOP <- mydata2[order(mydata2$P1df),] 
head(TOP,10)

manhattanPlot(p=mydata2$P1df,chromosome=mydata2$CHR, ylim=c(0,40), main="LMM Association Results for Transferrin")

qqPlot(pval=mydata2$P1df)

##### Similar, obtain plots for height ###

myrowH=row.names(grGamma.Height)

mydataH=grGamma.Height[,c(1,2,6,7,8,9,10)]

mydata2H=data.frame(myrowH,mydataH)

mydata2H=mydata2H[,c(2,1,3,4,5,6,7,8)]
names(mydata2H)=c("CHR","SNP", "BP", "N", "BETA", "SE","chi2.1df","P1df")

TOPH <- mydata2H[order(mydata2H$P1df),] 
head(TOPH,10)

manhattanPlot(p=mydata2H$P1df,chromosome=mydata2H$CHR, main="Association Results for Height")

qqPlot(pval=mydata2H$P1df)


#### Compare the qqplot for height from the mixed model to the plot from the linear regression analysis with PLINK  ####

### WHAT IS THE PROBLEM?  ## Can Use SNPrelate to estimate relatedness.

##  Create a GDS file for R from the PLINK files

library(gdsfmt)
library(SNPRelate)

bedfile<-"/Users/tathornt/Documents/SISG_2016_Analysis/Transferrin.bed" 
famfile<-"/Users/tathornt/Documents/SISG_2016_Analysis/Transferrin.fam" 
bimfile<-"/Users/tathornt/Documents/SISG_2016_Analysis/Transferrin.bim" 

snpgdsBED2GDS(bedfile, famfile, bimfile, "Transferringeno.gds")

genofile <- snpgdsOpen("Transferringeno.gds")
head(genofile)
head(read.gdsn(index.gdsn(genofile, "sample.id")))
head(read.gdsn(index.gdsn(genofile, "snp.id")))


ibd <- snpgdsIBDMoM(genofile, maf=0.05, missing.rate=0.05, num.thread=2)
ibd.coeff <- snpgdsIBDSelection(ibd)
head(ibd.coeff)

png("Transferrin_Relatedness.png")
plot(ibd.coeff$k0,ibd.coeff$kinship, xlim=c(0,1), ylim=c(0,.55),
    xlab="Probability of IBD=1", ylab="Kinship Coefficient", main="Transferrin Kinship")
dev.off()
```

# session 7 
```{r}
##################################################################################################################
##################################################################################################################
## PLINK script: recoding the data (for extraction later) and do GxE with dichotomous Exposure variable

# plink --bfile Transferrin --chr 3 --from-kb 134840 --to-kb 135052 --recodeA --out  TFsnps

### Analysis using ALL SNPs, --covar is the other variance that you want to test 
# interaction for 

# plink --bfile Transferrin --gxe --covar covD.dat --pheno Tr.pheno --out fullGxEanalysis

### Analysis using Only SNPs in TF gene, restricted to a particular region 

# plink --bfile Transferrin --chr 3 --from-kb 134840 --to-kb 135052 --gxe --covar covD.dat --pheno Tr.pheno --out TFGxEanalysisD

### Try to run interaction analysis with quantitative Exposure, continuous, this doesn't work for continuous ... so this fails, and we will try to do this in R 

# plink --bfile Transferrin --chr 3 --from-kb 134840 --to-kb 135052 --gxe --covar covC.dat --pheno Tr.pheno --out TFGxEanalysisC 

##################################################################################################################
##################################################################################################################
### R Scripts : Reading data into R and getting rid of missing phenotypes
setwd("/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/plink-1.07-mac-intel/")

snps = read.table("TFsnps.raw", header = T) 
phenotypes = read.table("/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/data/SISG_Files/Data_Files/Tr.pheno", header = F)
envC = read.table("/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/data/SISG_Files/Ex7/covC.dat", header = F)

missing.phenotypes = which(is.na(phenotypes[,3])) # clean up missingness
Z = as.matrix(snps[-missing.phenotypes,7:30])
y = as.vector(phenotypes[-missing.phenotypes,3])
E = as.vector(envC[-missing.phenotypes,3])

sum(is.na(Z)) ## this gives us the number of SNPs that are missing

w.missing = which(apply(is.na(Z),1,sum) > 0) ## This figures out which subjects have ANY missing values

Z = Z[-w.missing,]  ## now we get rid of the subjects with any missing SNPs
y = y[-w.missing]   ## BE CAREFUL: because we are over-writing the variable, don't run this line more than once by accident.
E = E[-w.missing]

sum(is.na(Z))
sum(is.na(y)) ## Now we see that there is no missingness in either the Z or the y.


##################################################################################################################
##################################################################################################################
### R Scripts : Marginal Association Test for GxE 

pvs = rep(NA, ncol(Z))

for (j in 1:ncol(Z)){
    mod = lm(y~Z[,j]*E)
    pvs[j] = summary(mod)$coef[4,4] ### Need to make sure plucking off the correct value
}

pvs

##################################################################################################################
##################################################################################################################
### R Scripts : 2-df test

pvs.2df = rep(NA, ncol(Z))

for (j in 1:ncol(Z)) {
    mod0 = lm(y~E)
    mod1 = lm(y~Z[,j]*E)
    pvs.2df[j] = anova(mod1,mod0)$P[2]
}
pvs.2df # looks like you have smaller P-value, but this is main+interaction effect, so you don't know whether there is really interaction 

##################################################################################################################
##################################################################################################################
### R Scripts : Simulate outcome

set.seed(150)
n = length(y)
y.new = 5*(E^2) + rnorm(n, 0, 1)


pvs = rep(NA, ncol(Z))

for (j in 1:ncol(Z)){
    mod = lm(y.new~Z[,j]*E)
    pvs[j] = summary(mod)$coef[4,4] ### Need to make sure plucking off the correct value
}

pvs

##################################################################################################################
##################################################################################################################
## PLINK script: testing for gene-gene interactions

### Analysis using ALL SNPs

# plink --bfile Transferrin --epistasis --pheno Tr_dich.pheno --out fullGxGanalysis


### Analysis using Only SNPs in TF gene, epistatic interaction between pairwise SNPs

# plink --bfile Transferrin --epistasis --chr 3 --from-kb 134840 --to-kb 135052 --pheno Tr_dich.pheno --out TFGxGanalysis


### Case Only analysis, assumption of indepdence of SNPs, no LD between SNPs, so specify the distance between SNPs, e.g. 1kb 

# plink --bfile Transferrin --fast-epistasis --case-only --chr 3 --from-kb 134840 --to-kb 135052 --pheno Tr_dich.pheno --out TFGxG_CO_analysis 

# plink --bfile Transferrin --fast-epistasis --case-only --gap 1  --chr 3 --from-kb 134840 --to-kb 135052 --pheno Tr_dich.pheno --out TFGxG_CO_analysis 
```

# session 8 
```{r}
##################################################################################################################
##################################################################################################################
### R Scripts: let's read Gene1 into R and look at the MAFs.

Z = as.matrix(read.table("/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/data/SISG_Files/Ex8/Gene1.txt", header = F))

maf = apply(Z,2,mean)/2 ## calculate the mean of each column and divide by 2 to get the maf, why this gives you maf? 
maf
maf = colMeans(Z)/2
maf
hist(maf) ## plot histogram
hist(maf[which(maf<0.05)])  ## Zoomed histogram (focus on really small values)


##################################################################################################################
##################################################################################################################
### R Scripts: test for association between each variant in Gene1 and Trait1

y.c = scan("/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/data/SISG_Files/Ex8/Trait1.txt") ## read in the values for trait 1
hist(y.c)
?scan
class(y.c)

pvs = rep(NA, ncol(Z))
length(pvs)

for (j in seq(ncol(Z))) {
  pvs[j] = summary(lm(y.c~Z[,j]))$coef[2,4]  ## test for association between y.c and each SNP
}
pvs
p.adjust(pvs, "bonf")  ## adjust p-values for multiple testing

##################################################################################################################
##################################################################################################################
### R Scripts: test for association between the variants in Gene1 and Trait1.

rvs = which(maf<0.03)  ## Set the threshold to be 0.03
rvs
### CAST: Binary collapsing

C = as.numeric(apply(Z[,rvs],1,sum)>0)  ## figures out if each person has any rare variants, ## i.e. the sum of their variants in additive mode would be greater than 0.
C
summary(lm(y.c~C))


### MZ Test

C = apply(Z[,rvs],1,sum)  ## number of rare variants each person haz
summary(lm(y.c~C))


### Weighted Count, different weighted methods 

weights = 1/sqrt(maf[rvs])
C = Z[,rvs]%*%weights ## Weighted sum
summary(lm(y.c~C))

weights = 1/maf[rvs] ## alternative weights
C = Z[,rvs]%*%weights
summary(lm(y.c~C))

weights = (1/maf[rvs])^2 ## alternative weights
C = Z[,rvs]%*%weights
summary(lm(y.c~C)) # all significant effects go away 

weights = (1/maf[rvs])^(1/3) ## alternative weights
C = Z[,rvs]%*%weights
summary(lm(y.c~C))

##################################################################################################################
##################################################################################################################
### R Scripts: test for association between the variants in Gene2 and Trait2.

Z = as.matrix(read.table("/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/data/SISG_Files/Ex8/Gene2.txt", header = F))
maf = apply(Z,2,mean)/2 ## calculate the mean of each column and divide by 2 to get the maf
y.c = scan("/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/data/SISG_Files/Ex8/Trait2.txt") ## read in the values for trait 1


rvs = which(maf<0.03)  ## Set the threshold to be 0.03


### CAST: Binary collapsing

C = as.numeric(apply(Z[,rvs],1,sum)>0)  ## figures out if each person has any rare variants,
                                        ## i.e. the sum of their variants in additive mode would be greater than 0.
summary(lm(y.c~C))


### MZ Test

C = apply(Z[,rvs],1,sum)  ## number of rare variants each person haz
summary(lm(y.c~C))


### Weighted Count

weights = 1/sqrt(maf[rvs])
C = Z[,rvs]%*%weights ## Weighted sum
summary(lm(y.c~C))


##################################################################################################################
##################################################################################################################
### R Scripts: test for association between the variants in Gene3 and Trait3.

Z = as.matrix(read.table("/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/data/SISG_Files/Ex8/Gene3.txt", header = F))
maf = apply(Z,2,mean)/2 ## calculate the mean of each column and divide by 2 to get the maf
y.c = scan("/Users/ruijuanli/Desktop/2016_summer/summer_institute/module10_GWAS/data/SISG_Files/Ex8/Trait3.txt") ## read in the values for trait 1


### CAST: Binary collapsing

rvs = which(maf<0.05)  ## Set the threshold to be 0.05
C = as.numeric(apply(Z[,rvs],1,sum)>0)
summary(lm(y.c~C))


rvs = which(maf<0.03)  ## Set the threshold to be 0.03
C = as.numeric(apply(Z[,rvs],1,sum)>0)
summary(lm(y.c~C))


rvs = which(maf<0.01)  ## Set the threshold to be 0.01
C = as.numeric(apply(Z[,rvs],1,sum)>0)
summary(lm(y.c~C))


rvs = which(maf<0.005)  ## Set the threshold to be 0.005
C = as.numeric(apply(Z[,rvs],1,sum)>0)
summary(lm(y.c~C))

# using different threshold gives you different result
### MZ Test

rvs = which(maf<0.05)  ## Set the threshold to be 0.05
C = apply(Z[,rvs],1,sum)
summary(lm(y.c~C))

rvs = which(maf<0.03)  ## Set the threshold to be 0.03
C = apply(Z[,rvs],1,sum)
summary(lm(y.c~C))

rvs = which(maf<0.01)  ## Set the threshold to be 0.01
C = apply(Z[,rvs],1,sum)
summary(lm(y.c~C))

rvs = which(maf<0.005)  ## Set the threshold to be 0.005
C = apply(Z[,rvs],1,sum)
summary(lm(y.c~C))


### Weighted Count

rvs = which(maf<0.05)  ## Set the threshold to be 0.05
weights = 1/maf[rvs]
C = Z[,rvs]%*%weights ## Weighted sum
summary(lm(y.c~C))
# by upweight rarer variants, you again are able to get significance 

weights = 1/maf ## DO NOT RESTRICT ANALYSIS TO RARE VARIANTS
C = Z%*%weights
summary(lm(y.c~C))
# choosing particular weights, threshold can change your results. 
```


















